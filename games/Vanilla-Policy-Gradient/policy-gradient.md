# Policy Gradient Tutorial

A vanilla implementation of Monte Carlo Policy Gradients.

Running the code : 

```
julia Policy_Gradient_Vanilla.jl
```
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:10:02.179000+04:00",
     "start_time": "2020-08-11T18:09:21.430Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1278\n",
      "┌ Warning: Package Flux does not have Zygote in its dependencies:\n",
      "│ - If you have Flux checked out for development and have\n",
      "│   added Zygote as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with Flux\n",
      "└ Loading Zygote into Flux from project dependency, future warnings for Flux are suppressed.\n",
      "┌ Warning: Package MacroTools does not have Markdown in its dependencies:\n",
      "│ - If you have MacroTools checked out for development and have\n",
      "│   added Markdown as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with MacroTools\n",
      "└ Loading Markdown into MacroTools from project dependency, future warnings for MacroTools are suppressed.\n",
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for ZygoteRules [700de1a5-db45-46bc-99cf-38207098b444]\n",
      "│   exception = Required dependency MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] failed to load from a cache file.\n",
      "└ @ Base loading.jl:1042\n",
      "┌ Warning: Package MacroTools does not have Markdown in its dependencies:\n",
      "│ - If you have MacroTools checked out for development and have\n",
      "│   added Markdown as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with MacroTools\n",
      "└ Loading Markdown into MacroTools from project dependency, future warnings for MacroTools are suppressed.\n",
      "┌ Warning: Package Requires does not have UUIDs in its dependencies:\n",
      "│ - If you have Requires checked out for development and have\n",
      "│   added UUIDs as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with Requires\n",
      "└ Loading UUIDs into Requires from project dependency, future warnings for Requires are suppressed.\n",
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for ChainRules [082447d4-558c-5d27-93f4-14fc19e9eca2]\n",
      "│   exception = Required dependency Requires [ae029012-a4dd-5104-9daa-d747884805df] failed to load from a cache file.\n",
      "└ @ Base loading.jl:1042\n",
      "┌ Warning: Package Requires does not have UUIDs in its dependencies:\n",
      "│ - If you have Requires checked out for development and have\n",
      "│   added UUIDs as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with Requires\n",
      "└ Loading UUIDs into Requires from project dependency, future warnings for Requires are suppressed.\n",
      "ERROR: LoadError: ArgumentError: Package SpecialFunctions does not have OpenSpecFun_jll in its dependencies:\n",
      "- If you have SpecialFunctions checked out for development and have\n",
      "  added OpenSpecFun_jll as a dependency but haven't updated your primary\n",
      "  environment's manifest file, try `Pkg.resolve()`.\n",
      "- Otherwise you may need to report an issue with SpecialFunctions\n",
      "Stacktrace:\n",
      " [1] require(::Module, ::Symbol) at ./loading.jl:906\n",
      " [2] include(::Function, ::Module, ::String) at ./Base.jl:380\n",
      " [3] include(::Module, ::String) at ./Base.jl:368\n",
      " [4] top-level scope at none:2\n",
      " [5] eval at ./boot.jl:331 [inlined]\n",
      " [6] eval(::Expr) at ./client.jl:467\n",
      " [7] top-level scope at ./none:3\n",
      "in expression starting at /home/subhaditya/.julia/packages/SpecialFunctions/LC8dm/src/SpecialFunctions.jl:3\n",
      "ERROR: LoadError: LoadError: LoadError: Failed to precompile SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] to /home/subhaditya/.julia/compiled/v1.5/SpecialFunctions/78gOt_L66GW.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at ./error.jl:33\n",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1290\n",
      " [3] _require(::Base.PkgId) at ./loading.jl:1030\n",
      " [4] require(::Base.PkgId) at ./loading.jl:928\n",
      " [5] require(::Module, ::Symbol) at ./loading.jl:923\n",
      " [6] include(::Function, ::Module, ::String) at ./Base.jl:380\n",
      " [7] include at ./Base.jl:368 [inlined]\n",
      " [8] include(::String) at /home/subhaditya/.julia/packages/Zygote/seGHk/src/forward/Forward.jl:1\n",
      " [9] top-level scope at /home/subhaditya/.julia/packages/Zygote/seGHk/src/forward/Forward.jl:11\n",
      " [10] include(::Function, ::Module, ::String) at ./Base.jl:380\n",
      " [11] include at ./Base.jl:368 [inlined]\n",
      " [12] include(::String) at /home/subhaditya/.julia/packages/Zygote/seGHk/src/Zygote.jl:1\n",
      " [13] top-level scope at /home/subhaditya/.julia/packages/Zygote/seGHk/src/Zygote.jl:22\n",
      " [14] include(::Function, ::Module, ::String) at ./Base.jl:380\n",
      " [15] include(::Module, ::String) at ./Base.jl:368\n",
      " [16] top-level scope at none:2\n",
      " [17] eval at ./boot.jl:331 [inlined]\n",
      " [18] eval(::Expr) at ./client.jl:467\n",
      " [19] top-level scope at ./none:3\n",
      "in expression starting at /home/subhaditya/.julia/packages/Zygote/seGHk/src/forward/number.jl:1\n",
      "in expression starting at /home/subhaditya/.julia/packages/Zygote/seGHk/src/forward/Forward.jl:11\n",
      "in expression starting at /home/subhaditya/.julia/packages/Zygote/seGHk/src/Zygote.jl:22\n",
      "ERROR: LoadError: Failed to precompile Zygote [e88e6eb3-aa80-5325-afca-941959d7151f] to /home/subhaditya/.julia/compiled/v1.5/Zygote/4kbLI_L66GW.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at ./error.jl:33\n",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1290\n",
      " [3] _require(::Base.PkgId) at ./loading.jl:1030\n",
      " [4] require(::Base.PkgId) at ./loading.jl:928\n",
      " [5] require(::Module, ::Symbol) at ./loading.jl:923\n",
      " [6] include(::Function, ::Module, ::String) at ./Base.jl:380\n",
      " [7] include(::Module, ::String) at ./Base.jl:368\n",
      " [8] top-level scope at none:2\n",
      " [9] eval at ./boot.jl:331 [inlined]\n",
      " [10] eval(::Expr) at ./client.jl:467\n",
      " [11] top-level scope at ./none:3\n",
      "in expression starting at /home/subhaditya/.julia/packages/Flux/05b38/src/Flux.jl:7\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Failed to precompile Flux [587475ba-b771-5e3f-ad9e-33799f191a9c] to /home/subhaditya/.julia/compiled/v1.5/Flux/QdkVy_L66GW.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Flux [587475ba-b771-5e3f-ad9e-33799f191a9c] to /home/subhaditya/.julia/compiled/v1.5/Flux/QdkVy_L66GW.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1290",
      " [3] _require(::Base.PkgId) at ./loading.jl:1030",
      " [4] require(::Base.PkgId) at ./loading.jl:928",
      " [5] require(::Module, ::Symbol) at ./loading.jl:923",
      " [6] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Metalhead:trainimgs, CIFAR10\n",
    "using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T21:52:29.839000+04:00",
     "start_time": "2020-08-11T17:52:25.688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getarray (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getarray(X) = Float32.(permutedims(channelview(X), (2, 3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T21:47:47.459000+04:00",
     "start_time": "2020-08-11T17:47:47.448Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: trainimgs not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: trainimgs not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[7]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "X = trainimgs(CIFAR10)\n",
    "imgs = [getarray(X[i].img) for i in 1:50000];\n",
    "labels = onehotbatch([X[i].ground_truth.class for i in 1:50000],1:10);\n",
    "train = gpu.([(cat(imgs[i]..., dims = 4), labels[:,i]) for i in partition(1:49000, 100)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T16:29:25.375000+04:00",
     "start_time": "2020-08-11T12:28:59.367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  0  0  0  1  0  1  0  0  0  0  0  0  …  0  0  0  0  1  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  1  0  0  0  1  0  0  0  0  1  1\n",
       " 0  0  0  0  0  0  0  0  1  0  0  0  0     0  0  0  1  0  0  0  1  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  1  0  0  0  0  0  0  0  0  0  0     0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0  …  1  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  1  0  0  0  1  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  1  0  0  0  0  0  0  0  0  1     0  0  0  0  0  0  0  0  0  1  0  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valset = collect(49001:50000)\n",
    "valX = cat(imgs[valset]..., dims = 4) |> gpu\n",
    "valY = labels[:, valset] |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " chain(A::Tuple...) = Chain(mapreduce(collect, vcat, A)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_block(in_channels, out_channels) = (\n",
    "    Conv((3,3), in_channels => out_channels, relu, pad = (1,1), stride = (1,1)), \n",
    "    BatchNorm(out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_conv(in_channels, out_channels) = (\n",
    "    conv_block(in_channels, out_channels),\n",
    "    conv_block(out_channels, out_channels),\n",
    "    MaxPool((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:05.168000+04:00",
     "start_time": "2020-08-11T13:05:05.159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16 (generic function with 2 methods)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16(initial_channels, num_classes) = chain(\n",
    "    double_conv(initial_channels, 64),\n",
    "    double_conv(64,128),\n",
    "    conv_block(128, 256),\n",
    "    double_conv(256, 256),  \n",
    "    conv_block(256, 512),\n",
    "    double_conv(512, 512),\n",
    "    conv_block(512, 512),\n",
    "    double_conv(512, 512),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(512, 4096, relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, 4096, relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, num_classes), \n",
    "    softmax\n",
    "    ) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:08.454000+04:00",
     "start_time": "2020-08-11T13:05:08.040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>64, relu), BatchNorm(64), Conv((3, 3), 64=>64, relu), BatchNorm(64), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 64=>128, relu), BatchNorm(128), Conv((3, 3), 128=>128, relu), BatchNorm(128), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 128=>256, relu), BatchNorm(256), Conv((3, 3), 256=>256, relu), BatchNorm(256), Conv((3, 3), 256=>256, relu), BatchNorm(256), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 256=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), #36, Dense(512, 4096, relu), Dropout(0.5), Dense(4096, 4096, relu), Dropout(0.5), Dense(4096, 10), softmax)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:11.842000+04:00",
     "start_time": "2020-08-11T13:05:11.839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:12.481000+04:00",
     "start_time": "2020-08-11T13:05:12.447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:13.807000+04:00",
     "start_time": "2020-08-11T13:05:13.721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::Flux.var\"#throttled#20\"{Flux.var\"#throttled#16#21\"{Bool,Bool,var\"#39#40\",Int64}}) (generic function with 1 method)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb = throttle(() -> @show(accuracy(valX, valY)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:05:14.409000+04:00",
     "start_time": "2020-08-11T13:05:14.407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:07:16.455000+04:00",
     "start_time": "2020-08-11T13:05:14.799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(valX, valY) = 0.112\n",
      "accuracy(valX, valY) = 0.087\n",
      "accuracy(valX, valY) = 0.087\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException:\nInterruptException:\nStacktrace:\n [1] ntuple(::NNlib.var\"#4#5\"{Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},NTuple{6,Int64},Tuple{Int64,Int64,Int64}}, ::Int64) at ./ntuple.jl:17\n [2] output_size at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/dim_helpers/ConvDims.jl:120 [inlined]\n [3] im2col!(::SubArray{Float32,2,Array{Float32,3},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::SubArray{Float32,4,Array{Float32,5},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:190\n [4] macro expansion at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:53 [inlined]\n [5] (::NNlib.var\"#349#threadsfor_fun#160\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})(::Bool) at ./threadingconstructs.jl:81\n [6] (::NNlib.var\"#349#threadsfor_fun#160\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})() at ./threadingconstructs.jl:48",
     "output_type": "error",
     "traceback": [
      "TaskFailedException:\nInterruptException:\nStacktrace:\n [1] ntuple(::NNlib.var\"#4#5\"{Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},NTuple{6,Int64},Tuple{Int64,Int64,Int64}}, ::Int64) at ./ntuple.jl:17\n [2] output_size at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/dim_helpers/ConvDims.jl:120 [inlined]\n [3] im2col!(::SubArray{Float32,2,Array{Float32,3},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::SubArray{Float32,4,Array{Float32,5},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:190\n [4] macro expansion at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:53 [inlined]\n [5] (::NNlib.var\"#349#threadsfor_fun#160\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})(::Bool) at ./threadingconstructs.jl:81\n [6] (::NNlib.var\"#349#threadsfor_fun#160\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})() at ./threadingconstructs.jl:48",
      "",
      "Stacktrace:",
      " [1] wait at ./task.jl:267 [inlined]",
      " [2] threading_run(::Function) at ./threadingconstructs.jl:34",
      " [3] macro expansion at ./threadingconstructs.jl:93 [inlined]",
      " [4] conv_im2col!(::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}; col::Array{Float32,3}, alpha::Float32, beta::Float32) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:49",
      " [5] conv_im2col! at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/impl/conv_im2col.jl:30 [inlined]",
      " [6] #conv!#41 at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:53 [inlined]",
      " [7] conv!(::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::DenseConvDims{3,(3, 3, 1),256,256,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:53",
      " [8] conv!(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),256,256,(1, 1),(1, 1, 1, 1),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:70",
      " [9] conv! at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:70 [inlined]",
      " [10] conv(::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),256,256,(1, 1),(1, 1, 1, 1),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:116",
      " [11] conv(::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),256,256,(1, 1),(1, 1, 1, 1),(1, 1),false}) at /home/subhaditya/.julia/packages/NNlib/FAI3o/src/conv.jl:114",
      " [12] (::Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}})(::Array{Float32,4}) at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/layers/conv.jl:61",
      " [13] applychain(::Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},var\"#36#37\",Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dropout{Float64,Colon},Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dropout{Float64,Colon},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/layers/basic.jl:36 (repeats 13 times)",
      " [14] (::Chain{Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},BatchNorm{typeof(identity),Array{Float32,1},Array{Float32,1},Float32},MaxPool{2,4},var\"#36#37\",Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dropout{Float64,Colon},Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dropout{Float64,Colon},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}})(::Array{Float32,4}) at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/layers/basic.jl:38",
      " [15] accuracy(::Array{Float32,4}, ::Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}) at ./In[180]:1",
      " [16] macro expansion at ./show.jl:641 [inlined]",
      " [17] (::var\"#39#40\")() at ./In[181]:1",
      " [18] throttled at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/utils.jl:302 [inlined]",
      " [19] throttled at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/utils.jl:298 [inlined]",
      " [20] macro expansion at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:93 [inlined]",
      " [21] macro expansion at /home/subhaditya/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]",
      " [22] train!(::typeof(loss), ::Zygote.Params, ::Array{Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}},1}, ::ADAM; cb::Flux.var\"#throttled#20\"{Flux.var\"#throttled#16#21\"{Bool,Bool,var\"#39#40\",Int64}}) at /home/subhaditya/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:81",
      " [23] top-level scope at In[183]:1",
      " [24] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(m), train, opt, cb = evalcb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
